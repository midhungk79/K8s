
Task 5
=========================

Create a ServiceAccount with the name "my-serviceaccount". Attach a Role to that service account. Give the necessary permission to list,watch & get for the resource 'pods'.
With the help of "kubectl auth can-i command make sure the serviceaccount which you have created have the right permission


ubuntu@ip-172-31-10-92:~$ vi my-serviceaccount.yaml
ubuntu@ip-172-31-10-92:~$ vi my-serviceaccount.yaml
ubuntu@ip-172-31-10-92:~$ kubectl apply -f my-serviceaccount.yaml
serviceaccount/my-serviceaccount created
role.rbac.authorization.k8s.io/pod-reader configured
rolebinding.rbac.authorization.k8s.io/read-pods created
ubuntu@ip-172-31-10-92:~$ kubectl get sa my-serviceaccount
NAME                SECRETS   AGE
my-serviceaccount   0         14s
ubuntu@ip-172-31-10-92:~$ kubectl get role pod-reader
NAME         CREATED AT
pod-reader   2023-04-17T10:58:07Z
ubuntu@ip-172-31-10-92:~$ kubectl auth can-i get pods --as=system:serviceaccount:default:my-serviceaccount
yes
ubuntu@ip-172-31-10-92:~$ kubectl auth can-i list pods --as=system:serviceaccount:default:my-serviceaccount
yes
ubuntu@ip-172-31-10-92:~$ kubectl auth can-i watch pods --as=system:serviceaccount:default:my-serviceaccount
yes
ubuntu@ip-172-31-10-92:~$ 


my-serviceaccount.yaml code


apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-serviceaccount
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: pod-reader
subjects:
- kind: ServiceAccount
  name: my-serviceaccount
  namespace: default
  
  
Task 6
===========================

Deploy a sample application with 3 replicas and label those with the selector flag as frontend. Enable the kubernetes metrics server on the kubernetes cluster.
With the help of "kubernetes top" command list the pod resource usage. Sort the pods with the cpu and memory. Also list the node resource usage with top command

  
  ubuntu@ip-172-31-10-92:~$ vi frontend-deployment.yaml
ubuntu@ip-172-31-10-92:~$ kubectl apply -f frontend-deployment.yaml
deployment.apps/frontend created
ubuntu@ip-172-31-10-92:~$ kubectl get deployment frontend
NAME       READY   UP-TO-DATE   AVAILABLE   AGE
frontend   3/3     3            3           8s
ubuntu@ip-172-31-10-92:~$ kubectl get pods -l app=frontend
NAME                        READY   STATUS    RESTARTS   AGE
frontend-5b4864c967-5pnc6   1/1     Running   0          19s
frontend-5b4864c967-d2b4c   1/1     Running   0          19s
frontend-5b4864c967-hjq6v   1/1     Running   0          19s
ubuntu@ip-172-31-10-92:~$ kubectl get pods 
NAME                        READY   STATUS    RESTARTS   AGE
frontend-5b4864c967-5pnc6   1/1     Running   0          29s
frontend-5b4864c967-d2b4c   1/1     Running   0          29s
frontend-5b4864c967-hjq6v   1/1     Running   0          29s
ubuntu@ip-172-31-10-92:~$ kubectl get pods -l app=frontend
NAME                        READY   STATUS    RESTARTS   AGE
frontend-5b4864c967-5pnc6   1/1     Running   0          52s
frontend-5b4864c967-d2b4c   1/1     Running   0          52s
frontend-5b4864c967-hjq6v   1/1     Running   0          52s




frontend-deployment.yaml.  code as below. 

apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: nginx:latest



  
  
ubuntu@ip-172-31-10-92:~$ kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
serviceaccount/metrics-server created
clusterrole.rbac.authorization.k8s.io/system:aggregated-metrics-reader created
clusterrole.rbac.authorization.k8s.io/system:metrics-server created
rolebinding.rbac.authorization.k8s.io/metrics-server-auth-reader created
clusterrolebinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator created
clusterrolebinding.rbac.authorization.k8s.io/system:metrics-server created
service/metrics-server created
deployment.apps/metrics-server created
apiservice.apiregistration.k8s.io/v1beta1.metrics.k8s.io created


while checking  reosuce usage getting error as below.  


kubectl top pods --sort-by=cpu
kubectl top pods --sort-by=memory


ubuntu@ip-172-31-10-92:~$ kubectl top pods --sort-by=cpu
Error from server (ServiceUnavailable): the server is currently unable to handle the request (get pods.metrics.k8s.io)
ubuntu@ip-172-31-10-92:~$ kubectl top pods --sort-by=memory
Error from server (ServiceUnavailable): the server is currently unable to handle the request (get pods.metrics.k8s.io)
ubuntu@ip-172-31-10-92:~$ kubectl top nodes




so edited yaml file  added code as below.

included this line  - --kubelet-insecure-tls=true

 spec:
      containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=4443
        - --kubelet-insecure-tls=true



ubuntu@ip-172-31-10-92:~$ cat components.yaml 
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    k8s-app: metrics-server
    rbac.authorization.k8s.io/aggregate-to-admin: "true"
    rbac.authorization.k8s.io/aggregate-to-edit: "true"
    rbac.authorization.k8s.io/aggregate-to-view: "true"
  name: system:aggregated-metrics-reader
rules:
- apiGroups:
  - metrics.k8s.io
  resources:
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    k8s-app: metrics-server
  name: system:metrics-server
rules:
- apiGroups:
  - ""
  resources:
  - pods
  - nodes
  - nodes/stats
  - namespaces
  - configmaps
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server-auth-reader
  namespace: kube-system
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: extension-apiserver-authentication-reader
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server:system:auth-delegator
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:auth-delegator
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    k8s-app: metrics-server
  name: system:metrics-server
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:metrics-server
subjects:
- kind: ServiceAccount
  name: metrics-server
  namespace: kube-system
---
apiVersion: v1
kind: Service
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server
  namespace: kube-system
spec:
  ports:
  - name: https
    port: 443
    protocol: TCP
    targetPort: https
  selector:
    k8s-app: metrics-server
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    k8s-app: metrics-server
  name: metrics-server
  namespace: kube-system
spec:
  selector:
    matchLabels:
      k8s-app: metrics-server
  strategy:
    rollingUpdate:
      maxUnavailable: 0
  template:
    metadata:
      labels:
        k8s-app: metrics-server
    spec:
      containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=4443
        - --kubelet-insecure-tls=true
        - --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname
        - --kubelet-use-node-status-port
        - --metric-resolution=15s
        image: k8s.gcr.io/metrics-server/metrics-server:v0.5.2
        imagePullPolicy: IfNotPresent
        livenessProbe:
          failureThreshold: 3
          httpGet:
            path: /livez
            port: https
            scheme: HTTPS
          periodSeconds: 10
        name: metrics-server
        ports:
        - containerPort: 4443
          name: https
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /readyz
            port: https
            scheme: HTTPS
          initialDelaySeconds: 20
          periodSeconds: 10
        resources:
          requests:
            cpu: 100m
            memory: 200Mi
        securityContext:
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        volumeMounts:
        - mountPath: /tmp
          name: tmp-dir
      nodeSelector:
        kubernetes.io/os: linux
      priorityClassName: system-cluster-critical
      serviceAccountName: metrics-server
      volumes:
      - emptyDir: {}
        name: tmp-dir
---
apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  labels:
    k8s-app: metrics-server
  name: v1beta1.metrics.k8s.io
spec:
  group: metrics.k8s.io
  groupPriorityMinimum: 100
  insecureSkipTLSVerify: true
  service:
    name: metrics-server
    namespace: kube-system
  version: v1beta1
  versionPriority: 100

ubuntu@ip-172-31-10-92:~$ 


 spec:
      containers:
      - args:
        - --cert-dir=/tmp
        - --secure-port=4443
        - --kubelet-insecure-tls=true



ubuntu@ip-172-31-10-92:~$ kubectl top nodes
NAME              CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%   
ip-172-31-10-92   92m          4%     1056Mi          13%       
ip-172-31-15-69   26m          1%     518Mi           6%        
ubuntu@ip-172-31-10-92:~$ 
  
  
  
  ubuntu@ip-172-31-10-92:~$ kubectl top pods --sort-by=cpu
NAME                        CPU(cores)   MEMORY(bytes)   
frontend-5b4864c967-5pnc6   0m           2Mi             
frontend-5b4864c967-d2b4c   0m           8Mi             
frontend-5b4864c967-hjq6v   0m           2Mi             
ubuntu@ip-172-31-10-92:~$ kubectl top pods --sort-by=memory
NAME                        CPU(cores)   MEMORY(bytes)   
frontend-5b4864c967-d2b4c   0m           8Mi             
frontend-5b4864c967-5pnc6   0m           2Mi             
frontend-5b4864c967-hjq6v   0m           2Mi             
ubuntu@ip-172-31-10-92:~$ 

  
  
Task 7
============================

Create a configMap with atleast 2 key-value pair, out of this one value should be Multi-line. Similarly create a 'secret' with the data to be passed as user and password as key value.Assign a base 64 value to those 2 keys. Pass this configuration data to inside a pod container at runtime as "ENV" variable. Make sure this passed configuration data can be accessed by the pod at run time



ubuntu@ip-172-31-10-92:~$ cat configmap1.yaml 
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-configmap
data:
  key1: value1
  key2: |
    This is a
    multi-line
    value
ubuntu@ip-172-31-10-92:~$ 




    value
ubuntu@ip-172-31-10-92:~$ cat secret1.yaml 
apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
  username: dXNlcg==
  password: cGFzc3dvcmQ=
ubuntu@ip-172-31-10-92:~$ 



ubuntu@ip-172-31-10-92:~$ cat pod1.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: my-container
    image: nginx
    env:
    - name: KEY1
      valueFrom:
        configMapKeyRef:
          name: my-configmap
          key: key1
    - name: KEY2
      valueFrom:
        configMapKeyRef:
          name: my-configmap
          key: key2
    - name: USERNAME
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: username
    - name: PASSWORD
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: password
ubuntu@ip-172-31-10-92:~$ 


ubuntu@ip-172-31-10-92:~$ kubectl apply -f configmap1.yaml 
configmap/my-configmap unchanged
ubuntu@ip-172-31-10-92:~$ kubectl apply -f secret1.yaml 
secret/my-secret unchanged
ubuntu@ip-172-31-10-92:~$ kubectl apply -f pod1.yaml 
pod/my-pod created
ubuntu@ip-172-31-10-92:~$ kubectl exec my-pod -- sh -c 'echo $KEY1'
error: unable to upgrade connection: container not found ("my-container")
ubuntu@ip-172-31-10-92:~$ kubectl delete pods,services,deployments --all^C
ubuntu@ip-172-31-10-92:~$ kubectl get pods
NAME     READY   STATUS         RESTARTS   AGE
my-pod   0/1     ErrImagePull   0          42s
ubuntu@ip-172-31-10-92:~$ vi pod1.yaml
ubuntu@ip-172-31-10-92:~$ kubectl delete pods,services,deployments --all
pod "my-pod" deleted
service "kubernetes" deleted
ubuntu@ip-172-31-10-92:~$ kubectl apply -f pod1.yaml 
pod/my-pod created
ubuntu@ip-172-31-10-92:~$ kubectl get pods
NAME     READY   STATUS    RESTARTS   AGE
my-pod   1/1     Running   0          6s
ubuntu@ip-172-31-10-92:~$ kubectl exec my-pod -- sh -c 'echo $KEY1'
value1
ubuntu@ip-172-31-10-92:~$ kubectl exec my-pod -- sh -c 'echo $KEY2'
This is a multi-line value
ubuntu@ip-172-31-10-92:~$ kubectl exec my-pod -- sh -c 'echo $USERNAME'
user
ubuntu@ip-172-31-10-92:~$ kubectl exec my-pod -- sh -c 'echo $PASSWORD'
password





  
  
  
  Task 8
=================

Pass the configuration data(ConfigMap and secret created on task 8) towards the container as a Configuration Volume. Make sure mouted path on the container have this config data,so that the container can access those values at runtime.

  
  
  
  
  ubuntu@ip-172-31-10-92:~$ > pod1.yaml 
ubuntu@ip-172-31-10-92:~$ vi pod1.yaml 
ubuntu@ip-172-31-10-92:~$ vi pod1.yaml 
ubuntu@ip-172-31-10-92:~$ kubectl apply -f pod1.yaml 
pod/my-pod created
ubuntu@ip-172-31-10-92:~$ kubectl exec -it my-pod -- /bin/bash
root@my-pod:/# cd /etc/config
root@my-pod:/etc/config# ls 
key1  key2
root@my-pod:/etc/config# cat key1
value1root@my-pod:/etc/config# cat key2
This is a multi-line
value for key2
root@my-pod:/etc/config# ls -la
total 16
drwxrwxrwx 3 root root 4096 Apr 18 06:13 .
drwxr-xr-x 1 root root 4096 Apr 18 06:13 ..
drwxr-xr-x 2 root root 4096 Apr 18 06:13 ..2023_04_18_06_13_27.1162358764
lrwxrwxrwx 1 root root   32 Apr 18 06:13 ..data -> ..2023_04_18_06_13_27.1162358764
lrwxrwxrwx 1 root root   11 Apr 18 06:13 key1 -> ..data/key1
lrwxrwxrwx 1 root root   11 Apr 18 06:13 key2 -> ..data/key2
root@my-pod:/etc/config# 

ubuntu@ip-172-31-10-92:~$ cat pod1.yaml 
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
  - name: my-container
    image: nginx
    volumeMounts:
    - name: config-volume
      mountPath: /etc/config
  volumes:
  - name: config-volume
    configMap:
      name: my-config-map
  - name: secret-volume
    secret:
      secretName: my-secret
ubuntu@ip-172-31-10-92:~$ 



Task 4 
=====================================================

Create a user with the name 'developer'. Attach a Role and bind the Role to the 'developer' user. In the 'Role' give the necessary permission to list,watch
& logs for the resource 'pods'. Changing the context to developer user, make sure the user have the assigned permission and its working too.



ubuntu@ip-172-31-0-85:~$ cat developer.yaml 
apiVersion: v1
kind: Namespace
metadata:
  name: developer

---

apiVersion: v1
kind: ServiceAccount
metadata:
  name: developer
  namespace: developer

---

kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  namespace: developer
  name: pod-reader
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["list", "watch", "get", "create", "update", "patch", "delete"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["list", "watch", "get", "create", "update", "patch", "delete"]

---

kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: read-pods
  namespace: developer
subjects:
- kind: ServiceAccount
  name: developer
  namespace: developer
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
ubuntu@ip-172-31-0-85:~$ 


in between got error for some reason kubectl command not worked , getting error as below. 

i was getting error when i set context.  so tried to delete all the created pods.  


ubuntu@ip-172-31-0-85:~$ kubectl delete pods,services,deployments --all
The connection to the server localhost:8080 was refused - did you specify the right host or port?

so to fix this. i used the below commands.  (it was due to the .kube folder was deleted automatically)

ubuntu@ip-172-31-0-85:~$ mkdir -p $HOME/.kube
ubuntu@ip-172-31-0-85:~$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
cp: overwrite '/home/ubuntu/.kube/config'? yes
ubuntu@ip-172-31-0-85:~$ sudo chown $(id -u):$(id -g) $HOME/.kube/config
ubuntu@ip-172-31-0-85:~$ kubectl delete pods,services,deployments --all
service "kubernetes" deleted

then i have run again the same dveveloper.yaml. 


ubuntu@ip-172-31-0-85:~$ kubectl apply -f developer.yaml 
namespace/developer unchanged
serviceaccount/developer unchanged
role.rbac.authorization.k8s.io/pod-reader unchanged
rolebinding.rbac.authorization.k8s.io/read-pods unchanged

ubuntu@ip-172-31-0-85:~$ kubectl config set-credentials developer --token=abc123
User "developer" set.

ubuntu@ip-172-31-0-85:~$ kubectl config set-context --current --user=developer --namespace=developer
Context "kubernetes-admin@kubernetes" modified.

while checking the permiison of the user whetehr he has permiison to watch and view pods. if he has permiision it will prompt yes.  but while cheking it i got error as below. 



ubuntu@ip-172-31-0-85:~$ kubectl auth can-i list pods
error: You must be logged in to the server (Unauthorized)

ubuntu@ip-172-31-0-85:~$ cp /etc/kubernetes/admin.conf $HOME/.kube/config
cp: cannot open '/etc/kubernetes/admin.conf' for reading: Permission denied

so i used below command to get rid of from this.  

ubuntu@ip-172-31-0-85:~$ sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config


now its shows yes. 

ubuntu@ip-172-31-0-85:~$ kubectl auth can-i list pods
yes

ubuntu@ip-172-31-0-85:~$ kubectl auth can-i list pods
yes
ubuntu@ip-172-31-0-85:~$ kubectl auth can-i logs pods
Warning: verb 'logs' is not a known verb
yes
ubuntu@ip-172-31-0-85:~$ 
ubuntu@ip-172-31-0-85:~$ kubectl auth can-i watch pods
yes
ubuntu@ip-172-31-0-85:~$ 














